{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "nav_menu": {
      "height": "279px",
      "width": "309px"
    },
    "toc": {
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "colab": {
      "name": "IntroductionToDataScienceFabLabAosta.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/federicomilani/intro_python_data_analysis/blob/main/IntroductionToDataScienceFabLabAosta.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPPTHRVtlpIz"
      },
      "source": [
        "**Fab Lab Aosta - Introduction to Data Science**\n",
        "\n",
        "> This notebook is adapted from the introductory project of [Hands on Machine Learning](https://github.com/ageron/handson-ml2/blob/master/02_end_to_end_machine_learning_project.ipynb)\n",
        "\n",
        "*Welcome to Machine Learning Housing Corp.! Your task is to predict median house values in Californian districts, given a number of features from these districts.*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SLs8CZBlpI2"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLyp-8KnlpI3"
      },
      "source": [
        "First, let's import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures. We also check that Python 3.5 or later is installed (although Python 2.x may work, it is deprecated so we strongly recommend you use Python 3 instead), as well as Scikit-Learn ≥0.20."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4E-D9s7lpI3"
      },
      "source": [
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# Where to save the figures\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"end_to_end_project\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4vRv9iClpI4"
      },
      "source": [
        "# Get the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKKpKL1DlpI4"
      },
      "source": [
        "import os\n",
        "import tarfile\n",
        "import urllib.request\n",
        "\n",
        "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml2/master/\"\n",
        "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
        "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
        "\n",
        "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
        "    if not os.path.isdir(housing_path):\n",
        "        os.makedirs(housing_path)\n",
        "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
        "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
        "    housing_tgz = tarfile.open(tgz_path)\n",
        "    housing_tgz.extractall(path=housing_path)\n",
        "    housing_tgz.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dckn6d12lpI5"
      },
      "source": [
        "fetch_housing_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkG5uE7CJ0TM"
      },
      "source": [
        "Write a `load_housing_data` method, which takes an optional `housing_path` argument, with a default value of `HOUSING_PATH`. The method must read a `housing.csv` file located in the `housing_path` and load its content in a Pandas dataframe, using the `read_csv` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QpZQf3clpI5"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_housing_data(housing_path=HOUSING_PATH):\n",
        "    # YOUR CODE HERE\n",
        "    # remember to return something"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75cQB8gVKxdA"
      },
      "source": [
        "Assign the result of the default execution of the method to `housing` variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVW77sZklpI5"
      },
      "source": [
        "housing = # YOUR CODE HERE\n",
        "housing.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FM5y7jGtMEZI"
      },
      "source": [
        "Get general information about the dataframe.\n",
        "> Is there a feature with missing data? Which one is it?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Es-pIYmJlpI7"
      },
      "source": [
        "# YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dvC6bXDLN1s"
      },
      "source": [
        "Print the distribution of the different values for the `ocean_proximity` feature. \n",
        "> How many times is `NEAR OCEAN` represented? What about `ISLAND`?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CA_XuzlhlpI7"
      },
      "source": [
        "# YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXyfGFYXLvqJ"
      },
      "source": [
        "Try to get statistical metrics for the `housing` dataframe. \n",
        "> What is the median latitude?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyY80fhAlpI7"
      },
      "source": [
        "# YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDjLOw6ytcyi"
      },
      "source": [
        "Next, we need to look at the values distribution for the different features. We can do that by creating histograms for each feature, using the `pandas.DataFrame.hist` function (suggested values: 50 bins and a `20,15` figure size. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOji2-ASlpI8"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "# YOUR CODE HERE\n",
        "save_fig(\"attribute_histogram_plots\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZL9gSccRlpI8"
      },
      "source": [
        "# to make this notebook's output identical at every run\n",
        "np.random.seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zl6rqmauugI_"
      },
      "source": [
        "> What does the `split_train_test` function do? How should it be changed to include a validation set?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mb9UgMyjlpI8"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# For illustration only. Sklearn has train_test_split()\n",
        "def split_train_test(data, test_ratio):\n",
        "    shuffled_indices = np.random.permutation(len(data))\n",
        "    test_set_size = int(len(data) * test_ratio)\n",
        "    test_indices = shuffled_indices[:test_set_size]\n",
        "    train_indices = shuffled_indices[test_set_size:]\n",
        "    return data.iloc[train_indices], data.iloc[test_indices]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83LWbDF0u9HU"
      },
      "source": [
        "Use the above function to create `train_set` and `test_set` starting from the `housing` dataframe. Let's use 80% of the data for the training set and the remaining 20% for the test set.\n",
        "> How many items are there in `train_set`? What about `test_set`?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woWnhT41lpI9"
      },
      "source": [
        "# YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Llx5Hm-2v8cD"
      },
      "source": [
        "Now let's look at the `median_income` values: create a histogram of its distribution, as done before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5g0gKrmlpJB"
      },
      "source": [
        "housing[\"median_income\"].hist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65hq319IwbRc"
      },
      "source": [
        "Let's now convert the continuous `median_income` values to a categorical attribute. For that, you need to use the `pandas.cut` function. The end result is adding a new column to the dataset (`income_cat`) which indicates the income category, from 1 to 5. In order to do that, you need to define the income values which will belong to each category; you can use `0., 1.5, 3.0, 4.5, 6., np.inf` as values for the `bins` argument "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEcvqGp5lpJB"
      },
      "source": [
        "housing[\"income_cat\"] = # YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QsK1WDxxfLO"
      },
      "source": [
        "Now look at how many items are there in each income category\n",
        "> How many rows are there in the dataset with a `median_income` between 1.5 and 3.0?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksKr5neVlpJB"
      },
      "source": [
        "# YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJC3QXb4x4p7"
      },
      "source": [
        "Let's represent them with a histogram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_XwZy_YlpJC"
      },
      "source": [
        "housing[\"income_cat\"].hist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTKyiONyyAy5"
      },
      "source": [
        "The next snippet uses a SciKit Learn to perform a stratified split based on the income category: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbN0XJHelpJC"
      },
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
        "for train_index, test_index in split.split(housing, housing[\"income_cat\"]):\n",
        "    strat_train_set = housing.loc[train_index]\n",
        "    strat_test_set = housing.loc[test_index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNCTYhNkycuk"
      },
      "source": [
        "The next line calculates the fraction of the rows for the test set in each category. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkAwfUaOlpJC"
      },
      "source": [
        "strat_test_set[\"income_cat\"].value_counts() / len(strat_test_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcJ2kURlyVl1"
      },
      "source": [
        "Now compare this values to the corresponding ratios for the whole dataset.\n",
        "> How do these data compare? Is this improving the representativeness of the test set?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0L5YMqHglpJD"
      },
      "source": [
        "# YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BP19Rwx7zHcf"
      },
      "source": [
        "Let's make this more quantitative and compare the relative sampling errors using a completely random split and a stratified one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMZz281QlpJD"
      },
      "source": [
        "def income_cat_proportions(data):\n",
        "    return data[\"income_cat\"].value_counts() / len(data)\n",
        "\n",
        "train_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)\n",
        "\n",
        "compare_props = pd.DataFrame({\n",
        "    \"Overall\": income_cat_proportions(housing),\n",
        "    \"Stratified\": income_cat_proportions(strat_test_set),\n",
        "    \"Random\": income_cat_proportions(test_set),\n",
        "}).sort_index()\n",
        "compare_props[\"Rand. %error\"] = 100 * compare_props[\"Random\"] / compare_props[\"Overall\"] - 100\n",
        "compare_props[\"Strat. %error\"] = 100 * compare_props[\"Stratified\"] / compare_props[\"Overall\"] - 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bCz7PgUlpJD"
      },
      "source": [
        "compare_props"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mO1INkZMy-e_"
      },
      "source": [
        "We can now drop the `income_cat` feature, which was only used to get a better split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Db6WKI-QlpJD"
      },
      "source": [
        "for set_ in (strat_train_set, strat_test_set):\n",
        "    set_.drop(\"income_cat\", axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgYwcYxOlpJE"
      },
      "source": [
        "# Discover and visualize the data to gain insights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0gagg5Izi58"
      },
      "source": [
        "Next, we'll try to visualize the dataset. First of all, let's set `housing` to a copy of the stratified training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFxG9lSVlpJE"
      },
      "source": [
        "housing = strat_train_set.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-l0oT17bzxQK"
      },
      "source": [
        "We can now use a scatter view to get a (bad) map of the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zH4uyq0jlpJE"
      },
      "source": [
        "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\")\n",
        "save_fig(\"bad_visualization_plot\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEuG93jBz3E9"
      },
      "source": [
        "The above command can be significantly improved by using semi-transparent points for the scatter plot; 90% trasnparency will get you a good visualization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHarQXI0lpJE"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "save_fig(\"better_visualization_plot\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HQiQR-G0VSQ"
      },
      "source": [
        "Finally, let's try to add one dimension to the scatter chart, namely the `median_house_value`, so that the map shows different colors for different house prices, immediately highlighting where it was more expensive to live in California in 1990. For this last challenge, you can use the `jet` colormap and add a legend for what the different colors mean; please refer to the `pandas.DataFrame.plot` documentation. \n",
        "PS. If you have strange visualization issues, try to add `sharex=False` to the arguments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIYagVR4lpJF"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "plt.legend()\n",
        "save_fig(\"housing_prices_scatterplot\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc76IMCs1wHK"
      },
      "source": [
        "Now let's calculate a correlation matrix\n",
        "> What does `corr_matrix` look like?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEbI3dyZlpJF"
      },
      "source": [
        "corr_matrix = housing.corr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sv4tbflJ11IG"
      },
      "source": [
        "Next, let's focus on the correlation between the different features and `median_house_value`\n",
        "> Which feature has the highest positive correlation with it?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmfMULa5lpJG"
      },
      "source": [
        "# YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdSQw6mu2f5K"
      },
      "source": [
        "Let's now get a scatter matrix for selected features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXcUYtFflpJG"
      },
      "source": [
        "# from pandas.tools.plotting import scatter_matrix # For older versions of Pandas\n",
        "from pandas.plotting import scatter_matrix\n",
        "\n",
        "attributes = [\"median_house_value\", \"median_income\", \"total_rooms\",\n",
        "              \"housing_median_age\"]\n",
        "scatter_matrix(housing[attributes], figsize=(12, 8))\n",
        "save_fig(\"scatter_matrix_plot\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EL9WYYXj2rt8"
      },
      "source": [
        "The next snippet creates a scatter plot relating income and house value.\n",
        "> What's wrong with it? What does it tell us about the `median_house_value` data^"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bEo2xbNlpJG"
      },
      "source": [
        "housing.plot(kind=\"scatter\", x=\"median_income\", y=\"median_house_value\",\n",
        "             alpha=0.1)\n",
        "plt.axis([0, 16, 0, 550000])\n",
        "save_fig(\"income_vs_house_value_scatterplot\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50MOSJW33Gtg"
      },
      "source": [
        "Next, let's create the following synthetic features and add them to the dataframe:\n",
        "- `rooms_per_household` (shown)\n",
        "- `bedrooms_per_room`\n",
        "- `population_per_household`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1wgnPEzlpJH"
      },
      "source": [
        "housing[\"rooms_per_household\"] = housing[\"total_rooms\"]/housing[\"households\"]\n",
        "housing[\"bedrooms_per_room\"] = # YOUR CODE HERE\n",
        "housing[\"population_per_household\"] = # YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABlB9w9b3i9A"
      },
      "source": [
        "Let's recalculate the correlation matrix and look at it\n",
        "> Do our synthetic features provide a better correlation than the values originally present in the dataset?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apOUCabHlpJH"
      },
      "source": [
        "corr_matrix = housing.corr()\n",
        "# YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWLg01lk35WV"
      },
      "source": [
        "Let's get a visual answer to the previous question by looking at a scatter plot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBr-CJzulpJH"
      },
      "source": [
        "housing.plot(kind=\"scatter\", x=\"rooms_per_household\", y=\"median_house_value\",\n",
        "             alpha=0.2)\n",
        "plt.axis([0, 5, 0, 520000])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRNPV2pU4Abs"
      },
      "source": [
        "Finally, let's look at a dataframe description:\n",
        "> Is there something wrong here? What is it?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHQPgPBrlpJI"
      },
      "source": [
        "housing.describe()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}